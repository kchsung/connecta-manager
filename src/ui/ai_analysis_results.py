"""
AI ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ì»´í¬ë„ŒíŠ¸
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import json
import os
import numpy as np
import time
from ..db.database import db_manager
from ..supabase.simple_client import simple_client
from ..constants.categories import (
    CATEGORY_OPTIONS,
    CATEGORY_DISPLAY_MAP_WITH_ALL,
)
from .streamlit_utils import display_tags


def _format_category(option: str) -> str:
    return CATEGORY_DISPLAY_MAP_WITH_ALL.get(option, option)

def render_ai_analysis_results():
    """AI ë¶„ì„ ê²°ê³¼ íƒ­"""
    st.subheader("ğŸ“Š ì¸ê³µì§€ëŠ¥ ë¶„ì„ ê²°ê³¼")
    st.markdown("AIê°€ ë¶„ì„í•œ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    try:
        # ê²€ìƒ‰ ë° í•„í„°ë§ ì˜µì…˜
        col1, col2, col3 = st.columns(3)
        
        with col1:
            search_term = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì´ë¦„, íƒœê·¸, IDë¡œ ê²€ìƒ‰")
        
        with col2:
            category_filter = st.selectbox(
                "ğŸ“‚ ì¹´í…Œê³ ë¦¬",
                ["ì „ì²´"] + get_categories(),
                format_func=_format_category
            )
        
        with col3:
            recommendations = ["ì „ì²´", "ì¶”ì²œ", "ì¡°ê±´ë¶€", "ë¹„ì¶”ì²œ"]
            recommendation_filter = st.selectbox("â­ ì¶”ì²œë„", recommendations)
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
        page_size = st.selectbox("ğŸ“„ í˜ì´ì§€ í¬ê¸°", [10, 25, 50, 100], index=1)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
            with st.spinner("ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘..."):
                # ì „ì²´ ê°œìˆ˜ ì¡°íšŒ
                total_count = get_ai_analysis_data_count(search_term, category_filter, recommendation_filter)
                
                if total_count == 0:
                    st.warning("ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                st.success(f"ì´ {total_count:,}ê°œì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # í˜ì´ì§€ë„¤ì´ì…˜
                total_pages = (total_count + page_size - 1) // page_size
                page = st.number_input("í˜ì´ì§€", min_value=1, max_value=total_pages, value=1)
                offset = (page - 1) * page_size
                
                # ë°ì´í„° ì¡°íšŒ
                analysis_data = get_ai_analysis_data(search_term, category_filter, recommendation_filter, page_size, offset)
                
                if not analysis_data:
                    st.warning("í•´ë‹¹ í˜ì´ì§€ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                # ê²°ê³¼ í‘œì‹œ
                display_analysis_results(analysis_data, total_count, page, total_pages)
    
    except Exception as e:
        st.error(f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def get_ai_analysis_data(search_term="", category_filter="ì „ì²´", recommendation_filter="ì „ì²´", limit=1000, offset=0):
    """AI ë¶„ì„ ë°ì´í„° ì¡°íšŒ (í˜ì´ì§• ì§€ì›) - ì¬ì‹œë„ ë¡œì§ í¬í•¨"""
    max_retries = 3
    retry_delay = 1
    
    for attempt in range(max_retries):
        try:
            client = simple_client.get_client()
            if not client:
                return []
            
            query = client.table("ai_influencer_analyses_new").select("*")
            
            # ê²€ìƒ‰ ì¡°ê±´
            if search_term:
                # ì´ë¦„, íƒœê·¸, influencer_idì—ì„œ ê²€ìƒ‰
                query = query.or_(f"name.ilike.%{search_term}%,tags.cs.{{{search_term}}},influencer_id.ilike.%{search_term}%")
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category_filter != "ì „ì²´":
                query = query.eq("category", category_filter)
            
            # ì¶”ì²œë„ í•„í„°
            if recommendation_filter != "ì „ì²´":
                query = query.eq("recommendation", recommendation_filter)
            
            response = query.order("analyzed_at", desc=True).range(offset, offset + limit - 1).execute()
            return response.data if response.data else []
            
        except Exception as e:
            error_msg = str(e)
            if "Server disconnected" in error_msg or "connection" in error_msg.lower():
                if attempt < max_retries - 1:
                    st.warning(f"ì„œë²„ ì—°ê²° ì˜¤ë¥˜. {retry_delay}s í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    st.error(f"ë¶„ì„ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨(ì¬ì‹œë„ ì´ˆê³¼): {error_msg}")
                    return []
            elif "invalid input value for enum recommendation_ko" in error_msg:
                st.error("ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ enum ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.warning("ğŸ”§ í•´ê²° ë°©ë²•:")
                st.markdown("""
                **1ë‹¨ê³„: ì•ˆì „í•œ ì§„ë‹¨**
                ```sql
                -- diagnose_enum_issue_safe.sql ì‹¤í–‰
                ```
                
                **2ë‹¨ê³„: ìµœì¢… ìˆ˜ì •**
                ```sql
                -- fix_recommendation_enum_final.sql ì‹¤í–‰
                ```
                
                **3ë‹¨ê³„: í™•ì¸**
                ```sql
                SELECT recommendation, COUNT(*) FROM ai_influencer_analyses GROUP BY recommendation;
                ```
                """)
                
                # ì„ì‹œ í•´ê²°ì±…: recommendation í•„í„° ì—†ì´ ì¡°íšŒ
                st.info("ğŸ”„ ì„ì‹œ í•´ê²°ì±…: ì¶”ì²œë„ í•„í„° ì—†ì´ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
                try:
                    query = client.table("ai_influencer_analyses_new").select("*")
                    if search_term:
                        query = query.or_(f"name.ilike.%{search_term}%,tags.cs.{{{search_term}}},influencer_id.ilike.%{search_term}%")
                    if category_filter != "ì „ì²´":
                        query = query.eq("category", category_filter)
                    # recommendation í•„í„°ëŠ” ì œì™¸
                    response = query.order("analyzed_at", desc=True).range(offset, offset + limit - 1).execute()
                    return response.data if response.data else []
                except Exception as fallback_error:
                    st.error(f"ì„ì‹œ í•´ê²°ì±…ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(fallback_error)}")
                    return []
            else:
                st.error(f"ë¶„ì„ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {error_msg}")
                return []
    
    return []

def get_ai_analysis_data_count(search_term="", category_filter="ì „ì²´", recommendation_filter="ì „ì²´"):
    """AI ë¶„ì„ ë°ì´í„° ì´ ê°œìˆ˜ ì¡°íšŒ - ì¬ì‹œë„ ë¡œì§ í¬í•¨"""
    max_retries = 3
    retry_delay = 1
    
    for attempt in range(max_retries):
        try:
            client = simple_client.get_client()
            if not client:
                return 0
            
            query = client.table("ai_influencer_analyses").select("id", count="exact")
            
            # ê²€ìƒ‰ ì¡°ê±´
            if search_term:
                # ì´ë¦„, íƒœê·¸, influencer_idì—ì„œ ê²€ìƒ‰
                query = query.or_(f"name.ilike.%{search_term}%,tags.cs.{{{search_term}}},influencer_id.ilike.%{search_term}%")
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category_filter != "ì „ì²´":
                query = query.eq("category", category_filter)
            
            # ì¶”ì²œë„ í•„í„°
            if recommendation_filter != "ì „ì²´":
                query = query.eq("recommendation", recommendation_filter)
            
            response = query.execute()
            return response.count if response.count else 0
            
        except Exception as e:
            error_msg = str(e)
            if "Server disconnected" in error_msg or "connection" in error_msg.lower():
                if attempt < max_retries - 1:
                    st.warning(f"ì„œë²„ ì—°ê²° ì˜¤ë¥˜. {retry_delay}s í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    st.error(f"ë¶„ì„ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨(ì¬ì‹œë„ ì´ˆê³¼): {error_msg}")
                    return 0
            elif "invalid input value for enum recommendation_ko" in error_msg:
                st.error("ğŸš¨ ë°ì´í„°ë² ì´ìŠ¤ enum ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.warning("ğŸ”§ í•´ê²° ë°©ë²•:")
                st.markdown("""
                **1ë‹¨ê³„: ì•ˆì „í•œ ì§„ë‹¨**
                ```sql
                -- diagnose_enum_issue_safe.sql ì‹¤í–‰
                ```
                
                **2ë‹¨ê³„: ìµœì¢… ìˆ˜ì •**
                ```sql
                -- fix_recommendation_enum_final.sql ì‹¤í–‰
                ```
                
                **3ë‹¨ê³„: í™•ì¸**
                ```sql
                SELECT recommendation, COUNT(*) FROM ai_influencer_analyses GROUP BY recommendation;
                ```
                """)
                
                # ì„ì‹œ í•´ê²°ì±…: recommendation í•„í„° ì—†ì´ ì¡°íšŒ
                st.info("ğŸ”„ ì„ì‹œ í•´ê²°ì±…: ì¶”ì²œë„ í•„í„° ì—†ì´ ê°œìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
                try:
                    query = client.table("ai_influencer_analyses").select("id", count="exact")
                    if search_term:
                        query = query.or_(f"name.ilike.%{search_term}%,tags.cs.{{{search_term}}},influencer_id.ilike.%{search_term}%")
                    if category_filter != "ì „ì²´":
                        query = query.eq("category", category_filter)
                    # recommendation í•„í„°ëŠ” ì œì™¸
                    response = query.execute()
                    return response.count if response.count else 0
                except Exception as fallback_error:
                    st.error(f"ì„ì‹œ í•´ê²°ì±…ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(fallback_error)}")
                    return 0
            else:
                st.error(f"ë¶„ì„ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {error_msg}")
                return 0
    
    return 0

def get_categories() -> List[str]:
    """í‘œì¤€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜"""
    return CATEGORY_OPTIONS

def display_analysis_results(analysis_data, total_count, current_page, total_pages):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown(f"### ğŸ“‹ ë¶„ì„ ê²°ê³¼ ({len(analysis_data)}ê°œ í‘œì‹œ ì¤‘, ì „ì²´ {total_count:,}ê°œ)")
    st.markdown(f"**í˜ì´ì§€ {current_page}/{total_pages}**")
    
    # ê²°ê³¼ í…Œì´ë¸”
    for i, analysis in enumerate(analysis_data):
        # None ê°’ ì•ˆì „ ì²˜ë¦¬
        name = analysis.get('name') or 'Unknown'
        alias = analysis.get('alias') or 'N/A'
        recommendation = analysis.get('recommendation') or 'N/A'
        with st.expander(f"ğŸ“Š {name} ({alias}) - {recommendation}"):
            display_analysis_detail(analysis)

def display_analysis_detail(analysis):
    """ê°œë³„ ë¶„ì„ ê²°ê³¼ ìƒì„¸ í‘œì‹œ"""
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ“‹ ê¸°ë³¸ ì •ë³´")
        # None ê°’ ì•ˆì „ ì²˜ë¦¬
        followers = analysis.get('followers') or 0
        followings = analysis.get('followings') or 0
        posts_count = analysis.get('posts_count') or 0
        analyzed_at = analysis.get('analyzed_at')
        
        basic_info = {
            "ì´ë¦„": analysis.get('name') or 'N/A',
            "ë³„ëª…": analysis.get('alias') or 'N/A',
            "í”Œë«í¼": analysis.get('platform') or 'N/A',
            "ì¹´í…Œê³ ë¦¬": analysis.get('category') or 'N/A',
            "íŒ”ë¡œì›Œ": f"{followers:,}",
            "íŒ”ë¡œì‰": f"{followings:,}",
            "ê²Œì‹œë¬¼ ìˆ˜": f"{posts_count:,}",
            "ì¶”ì²œë„": analysis.get('recommendation') or 'N/A',
            "ë¶„ì„ì¼": analyzed_at[:10] if analyzed_at else 'N/A'
        }
        
        for key, value in basic_info.items():
            st.write(f"**{key}**: {value}")
        
        # íƒœê·¸ í‘œì‹œ (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
        tags = analysis.get('tags', [])
        if tags:
            display_tags(tags, max_display=10)
    
    with col2:
        st.markdown("#### ğŸ“Š í‰ê°€ ì ìˆ˜")
        evaluation = analysis.get('evaluation', {})
        if evaluation:
            score_metrics = {
                "ì°¸ì—¬ë„": evaluation.get('engagement') or 0,
                "í™œë™ì„±": evaluation.get('activity') or 0,
                "ì†Œí†µë ¥": evaluation.get('communication') or 0,
                "ì„±ì¥ì„±": evaluation.get('growth_potential') or 0,
                "ì¢…í•©ì ìˆ˜": evaluation.get('overall_score') or 0
            }
            
            for metric, score in score_metrics.items():
                if isinstance(score, (int, float)) and score is not None:
                    st.metric(metric, f"{score:.1f}/10")
                else:
                    st.metric(metric, "N/A")
    
    # ìš”ì•½ ì •ë³´
    summary = analysis.get('summary')
    if summary and summary.strip():
        st.markdown("#### ğŸ“ ë¶„ì„ ìš”ì•½")
        st.write(summary)
    
    # ìƒì„¸ ë¶„ì„ ì„¹ì…˜ë“¤
    st.markdown("#### ğŸ” ìƒì„¸ ë¶„ì„")
    
    # í‰ê°€ ì„¹ì…˜
    if evaluation:
        display_analysis_section(evaluation, "ğŸ“Š í‰ê°€")
    
    # ì½˜í…ì¸  ë¶„ì„ ì„¹ì…˜
    content_analysis = analysis.get('content_analysis', {})
    if content_analysis:
        display_analysis_section(content_analysis, "ğŸ“ ì½˜í…ì¸  ë¶„ì„")
    
    # ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
    insights = analysis.get('insights', {})
    if insights:
        display_analysis_section(insights, "ğŸ’¡ ì¸ì‚¬ì´íŠ¸")
    
    # ì»¤ë¨¸ìŠ¤ ì§€í–¥ì„± ë¶„ì„ ì„¹ì…˜
    commerce_analysis = analysis.get('commerce_orientation_analysis', {})
    if commerce_analysis:
        display_analysis_section(commerce_analysis, "ğŸ›’ ì»¤ë¨¸ìŠ¤ ì§€í–¥ì„± ë¶„ì„")
    
    # ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì„¹ì…˜
    follow_network = analysis.get('follow_network_analysis', {})
    if follow_network:
        display_analysis_section(follow_network, "ğŸŒ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")
    
    # ëŒ“ê¸€ ì§„ì •ì„± ë¶„ì„ ì„¹ì…˜
    comment_analysis = analysis.get('comment_authenticity_analysis', {})
    if comment_analysis:
        display_analysis_section(comment_analysis, "ğŸ’¬ ëŒ“ê¸€ ì§„ì •ì„± ë¶„ì„")

def get_field_display_name(key):
    """í•„ë“œ í‚¤ë¥¼ í•œêµ­ì–´ í‘œì‹œëª…ìœ¼ë¡œ ë³€í™˜"""
    field_mapping = {
        # ê¸°ë³¸ ì •ë³´
        "name": "ì´ë¦„",
        "alias": "ë³„ëª…",
        "platform": "í”Œë«í¼",
        "category": "ì¹´í…Œê³ ë¦¬",
        "followers": "íŒ”ë¡œì›Œ ìˆ˜",
        "followings": "íŒ”ë¡œì‰ ìˆ˜",
        "posts_count": "ê²Œì‹œë¬¼ ìˆ˜",
        "tags": "íƒœê·¸",
        "recommendation": "ì¶”ì²œë„",
        "summary": "ìš”ì•½",
        
        # í‰ê°€ ì ìˆ˜
        "engagement": "ì°¸ì—¬ë„",
        "activity": "í™œë™ì„±",
        "communication": "ì†Œí†µë ¥",
        "growth_potential": "ì„±ì¥ì„±",
        "overall_score": "ì¢…í•©ì ìˆ˜",
        "brand_fit_comment": "ë¸Œëœë“œ ì í•©ì„± ì½”ë©˜íŠ¸",
        
        # ì½˜í…ì¸  ë¶„ì„
        "dominant_topics": "ì£¼ìš” ì£¼ì œ",
        "narrative_style": "ë‚´ëŸ¬í‹°ë¸Œ ìŠ¤íƒ€ì¼",
        "visual_style": "ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼",
        "audience_focus": "íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤",
        "content_goal_inference": "ì½˜í…ì¸  ëª©í‘œ ì¶”ë¡ ",
        "inferred_tone": "ì¶”ë¡ ëœ í†¤",
        "inference_confidence": "ì¶”ë¡  ì‹ ë¢°ë„",
        "content_type": "ì½˜í…ì¸  ìœ í˜•",
        "engagement_rate": "ì°¸ì—¬ìœ¨",
        
        # ì¸ì‚¬ì´íŠ¸
        "strengths": "ê°•ì ",
        "weaknesses": "ì•½ì ",
        "opportunities": "ê¸°íšŒ",
        "threats": "ìœ„í˜‘",
        "recommendations": "ì¶”ì²œì‚¬í•­",
        
        # ê¸°íƒ€
        "notes": "ë…¸íŠ¸",
        "additional_info": "ì¶”ê°€ ì •ë³´",
        "analysis_date": "ë¶„ì„ ë‚ ì§œ",
        "confidence_level": "ì‹ ë¢°ë„ ìˆ˜ì¤€",
        
        # ì»¤ë¨¸ìŠ¤ ì§€í–¥ì„±
        "interpretation": "í•´ì„",
        "bragging_signals": "ê³¼ì‹œ ì‹ í˜¸",
        "selling_effort_signals": "íŒë§¤ ë…¸ë ¥ ì‹ í˜¸",
        "creator_archetype": "í¬ë¦¬ì—ì´í„° ìœ í˜•",
        "primary_motivation": "ì£¼ìš” ë™ê¸°",
        "monetization_intent_level": "ìˆ˜ìµí™” ì„±í–¥ ì ìˆ˜",
        "bragging_orientation_level": "ê³¼ì‹œ ì§€í–¥ ì ìˆ˜",
        "content_fit_for_selling_score": "ì»¤ë¨¸ìŠ¤ ì í•©ë„ ì ìˆ˜"
    }
    
    return field_mapping.get(key, key)

def display_analysis_section(data, section_title):
    """ë¶„ì„ ì„¹ì…˜ ë°ì´í„°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í‘œì‹œ"""
    if not data:
        st.info("ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown(f"**{section_title}**")
    
    for key, value in data.items():
        display_name = get_field_display_name(key)
        
        if isinstance(value, dict):
            st.markdown(f"**{display_name}**:")
            for sub_key, sub_value in value.items():
                sub_display_name = get_field_display_name(sub_key)
                # None ê°’ ì•ˆì „ ì²˜ë¦¬
                safe_sub_value = sub_value if sub_value is not None else "ì—†ìŒ"
                st.write(f"  - {sub_display_name}: {safe_sub_value}")
        elif isinstance(value, list):
            if value:
                # ë¦¬ìŠ¤íŠ¸ ë‚´ None ê°’ë“¤ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                safe_values = [str(v) if v is not None else "ì—†ìŒ" for v in value]
                st.markdown(f"**{display_name}**: {', '.join(safe_values)}")
            else:
                st.markdown(f"**{display_name}**: ì—†ìŒ")
        else:
            if value is not None and value != "":
                st.markdown(f"**{display_name}**: {value}")
            else:
                st.markdown(f"**{display_name}**: ì—†ìŒ")
