"""
AI ë¶„ì„ ì‹¤í–‰ ê´€ë ¨ ì»´í¬ë„ŒíŠ¸
"""
import streamlit as st
import time
from ..supabase.simple_client import simple_client
from .ai_analysis_common import (
    get_completed_crawling_data, 
    get_completed_crawling_data_count,
    is_recently_analyzed_by_id,
    save_ai_analysis_result,
    perform_ai_analysis,
    transform_to_db_format
)

def render_ai_analysis_execution():
    """AI ë¶„ì„ ì‹¤í–‰ íƒ­"""
    st.subheader("ğŸš€ ì¸ê³µì§€ëŠ¥ ë¶„ì„ ì‹¤í–‰")
    st.markdown("í¬ë¡¤ë§ì´ ì™„ë£Œëœ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ AIë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # OpenAI API í‚¤ í™•ì¸
    import os
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        try:
            openai_api_key = st.secrets["OPENAI_API_KEY"]
        except (KeyError, AttributeError):
            openai_api_key = None
    
    if not openai_api_key or openai_api_key == "your-openai-api-key-here":
        st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
        
    # ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
    if "ai_analysis_running" not in st.session_state:
        st.session_state.ai_analysis_running = False
    if "ai_analysis_stop_requested" not in st.session_state:
        st.session_state.ai_analysis_stop_requested = False
    
    # ë¶„ì„ ì¤‘ì§€ ë²„íŠ¼ (ë¶„ì„ ì¤‘ì¼ ë•Œë§Œ í‘œì‹œ)
    if st.session_state.ai_analysis_running:
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("â¹ï¸ ë¶„ì„ ì¤‘ì§€", type="secondary", help="í˜„ì¬ ì§„í–‰ ì¤‘ì¸ AI ë¶„ì„ì„ ì¤‘ì§€í•©ë‹ˆë‹¤"):
                st.session_state.ai_analysis_stop_requested = True
                st.warning("ğŸ›‘ ë¶„ì„ ì¤‘ì§€ ìš”ì²­ë¨. í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í•­ëª© ì™„ë£Œ í›„ ì¤‘ì§€ë©ë‹ˆë‹¤.")
                st.rerun()
    
    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ (ë¶„ì„ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ í‘œì‹œ)
    if not st.session_state.ai_analysis_running:
        if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘", type="primary"):
            st.session_state.ai_analysis_running = True
            st.session_state.ai_analysis_stop_requested = False
            st.rerun()
    
    # ë¶„ì„ ì‹¤í–‰ ì¤‘ì¼ ë•Œ
    if st.session_state.ai_analysis_running:
        with st.spinner("AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
            result = execute_ai_analysis()
            
            # ë¶„ì„ ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.ai_analysis_running = False
            st.session_state.ai_analysis_stop_requested = False
            
            if result["success"]:
                if result.get("stopped", False):
                    st.warning("ğŸ›‘ AI ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.success("ğŸ‰ AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("âœ… ì„±ê³µ", result["analyzed_count"])
                with col2:
                    st.metric("â­ï¸ ê±´ë„ˆëœ€", result["skipped_count"])
                with col3:
                    st.metric("âŒ ì‹¤íŒ¨", result["failed_count"])
                with col4:
                    st.metric("ğŸ“Š ì´ ì²˜ë¦¬", result["total_count"])
                
                # ê±´ë„ˆë›´ ì´ìœ  ìƒì„¸ ì •ë³´ í‘œì‹œ
                if result.get("skipped_count", 0) > 0:
                    st.markdown("#### ğŸ“‹ ê±´ë„ˆë›´ ì´ìœ  ìƒì„¸")
                    skip_col1, skip_col2 = st.columns(2)
                    with skip_col1:
                        st.info(f"ğŸ• ìµœê·¼ 30ì¼ ì´ë‚´ ë¶„ì„ë¨: **{result.get('skipped_recent_analysis', 0)}ê°œ**")
                    with skip_col2:
                        st.info(f"ğŸ“ posts ë°ì´í„° ì—†ìŒ: **{result.get('skipped_no_posts', 0)}ê°œ**")
                
                
                # ì‹¤íŒ¨í•œ í•­ëª©ë“¤ í‘œì‹œ
                if result.get("failed_items"):
                    st.markdown("### âŒ ì‹¤íŒ¨í•œ í•­ëª©ë“¤")
                    with st.expander(f"ì‹¤íŒ¨í•œ {len(result['failed_items'])}ê°œ í•­ëª© ìƒì„¸ë³´ê¸°"):
                        for item in result["failed_items"]:
                            st.error(f"**ID: {item['id']}** - {item['error']}")
            else:
                st.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {result['error']}")

def execute_ai_analysis():
    """AI ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬) - ì•ˆì •í™” ë²„ì „"""
    try:
        # Supabase í´ë¼ì´ì–¸íŠ¸ 1íšŒ ìƒì„±/ì¬ì‚¬ìš©
        client = simple_client.get_client()
        if not client:
            return {"success": False, "error": "Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨"}

        # 1. ì „ì²´ ë°ì´í„° ê°œìˆ˜ (COMPLETE ìƒíƒœë§Œ)
        total_count = get_completed_crawling_data_count(client)
        if total_count == 0:
            return {"success": False, "error": "ë¶„ì„í•  í¬ë¡¤ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë””ë²„ê¹…: ì „ì²´ ë°ì´í„° ê°œìˆ˜ë„ í™•ì¸
        try:
            total_all_count = client.table("tb_instagram_crawling").select("id", count="exact").execute()
            st.info(f"ğŸ“Š ë°ì´í„° í˜„í™©: ì „ì²´ {total_all_count.count:,}ê°œ ì¤‘ ì™„ë£Œëœ í¬ë¡¤ë§ ë°ì´í„° {total_count:,}ê°œ (status='COMPLETE')")
        except:
            st.info(f"ì´ {total_count:,}ê°œì˜ ì™„ë£Œëœ í¬ë¡¤ë§ ë°ì´í„°(status='COMPLETE')ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        st.info("ë°°ì¹˜ ë‹¨ìœ„ë¡œ AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        batch_size = 50
        total_batches = (total_count + batch_size - 1) // batch_size

        analyzed_count = 0
        skipped_count = 0
        skipped_recent_analysis = 0  # ìµœê·¼ ë¶„ì„ìœ¼ë¡œ ê±´ë„ˆë›´ ê°œìˆ˜
        skipped_no_posts = 0  # postsê°€ ì—†ì–´ì„œ ê±´ë„ˆë›´ ê°œìˆ˜
        failed_count = 0
        processed_count = 0
        failed_items = []

        overall_progress_bar = st.progress(0)
        overall_status_text = st.empty()
        result_container = st.empty()

        UI_UPDATE_EVERY = 50  # ê°±ì‹  ì£¼ê¸°

        for batch_num in range(total_batches):
            # ì¤‘ì§€ ìš”ì²­ í™•ì¸
            if st.session_state.get("ai_analysis_stop_requested", False):
                st.warning("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return {
                    "success": True,
                    "stopped": True,
                    "analyzed_count": analyzed_count,
                    "skipped_count": skipped_count,
                    "skipped_recent_analysis": skipped_recent_analysis,
                    "skipped_no_posts": skipped_no_posts,
                    "failed_count": failed_count,
                    "total_count": total_count,
                    "failed_items": failed_items
                }
            
            offset = batch_num * batch_size
            batch_data = get_completed_crawling_data(client, limit=batch_size, offset=offset)
            
            if not batch_data:
                break

            # ë°°ì¹˜ ì§„í–‰ UI (ê°„ì†Œí™”)
            batch_progress_bar = st.progress(0)
            batch_status_text = st.empty()

            for index, data in enumerate(batch_data):
                # ê° í•­ëª© ì²˜ë¦¬ ì „ì—ë„ ì¤‘ì§€ ìš”ì²­ í™•ì¸
                if st.session_state.get("ai_analysis_stop_requested", False):
                    st.warning("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return {
                        "success": True,
                        "stopped": True,
                        "analyzed_count": analyzed_count,
                        "skipped_count": skipped_count,
                        "failed_count": failed_count,
                        "total_count": total_count,
                        "failed_items": failed_items
                    }
                
                current_id = data.get('id', 'unknown')
                
                try:
                    # ì „ì²´/ë°°ì¹˜ ì§„í–‰ë¥ 
                    overall_progress = (processed_count + index + 1) / total_count
                    overall_progress_bar.progress(overall_progress)
                    overall_status_text.text(
                        f"ì „ì²´ ì§„í–‰: {processed_count + index + 1:,}/{total_count:,} (ë°°ì¹˜ {batch_num + 1}/{total_batches})"
                    )

                    batch_progress = (index + 1) / len(batch_data)
                    batch_progress_bar.progress(batch_progress)
                    batch_status_text.text(f"ë°°ì¹˜ {batch_num + 1} ì§„í–‰: {index + 1}/{len(batch_data)} - {current_id}")

                    # 1) ìµœê·¼ ë¶„ì„ ì—¬ë¶€ ì²´í¬ (30ì¼ ì´ë‚´ ë¶„ì„ëœ ê²ƒì€ ê±´ë„ˆë›°ê¸°)
                    # ìƒˆë¡œìš´ ì¡°ê±´ì—ì„œëŠ” ai_analysis_status.is_analyzed = FALSEì¸ ê²ƒë§Œ ì¡°íšŒí•˜ë¯€ë¡œ
                    # 30ì¼ ì²´í¬ëŠ” ì„ íƒì ìœ¼ë¡œ ì ìš© (ê°•ì œ ì¬ë¶„ì„ ë°©ì§€ìš©)
                    if is_recently_analyzed_by_id(client, data["id"]):
                        skipped_count += 1
                        skipped_recent_analysis += 1
                        continue

                    # 2) ì…ë ¥ êµ¬ì„± (postsëŠ” ìë¥´ì§€ ì•ŠìŒ)
                    posts_content = data.get("posts", "") or ""
                    if not posts_content:
                        skipped_count += 1
                        skipped_no_posts += 1
                        continue

                    ai_input_data = {
                        "id": data.get("id", ""),
                        "description": data.get("description", "") or "",
                        "posts": posts_content
                    }

                    # 3) AI ë¶„ì„
                    analysis_result = perform_ai_analysis(ai_input_data)
                    if not analysis_result:
                        failed_items.append({"id": current_id, "error": "AI ë¶„ì„ ì‹¤íŒ¨"})
                        failed_count += 1
                        continue

                    # 4) ë³€í™˜
                    transformed_result = transform_to_db_format(ai_input_data, analysis_result, data["id"])
                    if not transformed_result:
                        failed_items.append({"id": current_id, "error": "ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨"})
                        failed_count += 1
                        continue

                    # 5) ì €ì¥
                    try:
                        save_ai_analysis_result(client, data, transformed_result, data["id"])
                        analyzed_count += 1
                    except Exception as se:
                        failed_items.append({"id": current_id, "error": f"ì €ì¥ ì‹¤íŒ¨: {str(se)}"})
                        failed_count += 1
                        continue

                    # UI ì—…ë°ì´íŠ¸(í¬ì†Œ)
                    if ((index + 1) % UI_UPDATE_EVERY == 0) or (index == len(batch_data) - 1):
                        try:
                            with result_container.container():
                                st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²°ê³¼")
                                c1, c2, c3, c4 = st.columns(4)
                                c1.metric("âœ… ì„±ê³µ", analyzed_count)
                                c2.metric("â­ï¸ ê±´ë„ˆëœ€", skipped_count)
                                c3.metric("âŒ ì‹¤íŒ¨", failed_count)
                                c4.metric("ğŸ“Š ì´ ì²˜ë¦¬", processed_count + index + 1)
                                
                                # ê±´ë„ˆë›´ ì´ìœ  ìƒì„¸ ì •ë³´
                                if skipped_count > 0:
                                    st.caption(f"ê±´ë„ˆë›´ ì´ìœ : ìµœê·¼ ë¶„ì„ {skipped_recent_analysis}ê°œ, posts ì—†ìŒ {skipped_no_posts}ê°œ")
                                
                                # ì¤‘ì§€ ìš”ì²­ ìƒíƒœ í‘œì‹œ
                                if st.session_state.get("ai_analysis_stop_requested", False):
                                    st.warning("ğŸ›‘ ë¶„ì„ ì¤‘ì§€ ìš”ì²­ë¨ - í˜„ì¬ í•­ëª© ì™„ë£Œ í›„ ì¤‘ì§€ë©ë‹ˆë‹¤.")
                        except Exception as ui_error:
                            # UI ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ë¶„ì„ì€ ê³„ì† ì§„í–‰
                            pass

                except Exception as e:
                    failed_items.append({"id": current_id, "error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"})
                    failed_count += 1
                    continue

            processed_count += len(batch_data)
            batch_progress_bar.empty()
            batch_status_text.empty()

            # ë°°ì¹˜ ê°„ íœ´ì‹ ìµœì†Œí™”(ë˜ëŠ” ì œê±°)
            if batch_num < total_batches - 1:
                time.sleep(0.1)

        overall_progress_bar.progress(1.0)
        overall_status_text.text("ë¶„ì„ ì™„ë£Œ!")

        with result_container.container():
            st.markdown("### ğŸ‰ AI ë¶„ì„ ìµœì¢… ê²°ê³¼")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("âœ… ì„±ê³µ", analyzed_count, delta=f"{(analyzed_count/total_count*100):.1f}%")
            c2.metric("â­ï¸ ê±´ë„ˆëœ€", skipped_count, delta=f"{(skipped_count/total_count*100):.1f}%")
            c3.metric("âŒ ì‹¤íŒ¨", failed_count, delta=f"{(failed_count/total_count*100):.1f}%")
            c4.metric("ğŸ“Š ì´ ì²˜ë¦¬", total_count, delta="100%")
            
            # ê±´ë„ˆë›´ ì´ìœ  ìƒì„¸ ì •ë³´ í‘œì‹œ
            if skipped_count > 0:
                st.markdown("#### ğŸ“‹ ê±´ë„ˆë›´ ì´ìœ  ìƒì„¸")
                skip_col1, skip_col2 = st.columns(2)
                with skip_col1:
                    st.info(f"ğŸ• ìµœê·¼ 30ì¼ ì´ë‚´ ë¶„ì„ë¨: **{skipped_recent_analysis}ê°œ**")
                with skip_col2:
                    st.info(f"ğŸ“ posts ë°ì´í„° ì—†ìŒ: **{skipped_no_posts}ê°œ**")

            if failed_items:
                st.markdown("### âŒ ì‹¤íŒ¨í•œ í•­ëª©ë“¤")
                with st.expander(f"ì‹¤íŒ¨í•œ {len(failed_items)}ê°œ í•­ëª© ìƒì„¸ë³´ê¸°"):
                    for item in failed_items:
                        st.error(f"**ID: {item['id']}** - {item['error']}")

        return {
            "success": True,
            "analyzed_count": analyzed_count,
            "skipped_count": skipped_count,
            "skipped_recent_analysis": skipped_recent_analysis,
            "skipped_no_posts": skipped_no_posts,
            "failed_count": failed_count,
            "total_count": total_count,
            "failed_items": failed_items
        }

    except Exception as e:
        return {"success": False, "error": str(e)}
