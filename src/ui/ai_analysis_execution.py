"""
AI ë¶„ì„ ì‹¤í–‰ ê´€ë ¨ ì»´í¬ë„ŒíŠ¸
"""
import streamlit as st
import time
from ..supabase.simple_client import simple_client
from .ai_analysis_common import (
    get_completed_crawling_data, 
    get_completed_crawling_data_count,
    is_recently_analyzed_by_id,
    save_ai_analysis_result,
    perform_ai_analysis,
    transform_to_db_format
)

def render_ai_analysis_execution():
    """AI ë¶„ì„ ì‹¤í–‰ íƒ­"""
    st.subheader("ğŸš€ ì¸ê³µì§€ëŠ¥ ë¶„ì„ ì‹¤í–‰")
    st.markdown("í¬ë¡¤ë§ì´ ì™„ë£Œëœ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ AIë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # OpenAI API í‚¤ í™•ì¸
    import os
    openai_api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
    
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    st.success("âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘", type="primary"):
        with st.spinner("AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
            result = execute_ai_analysis()
            
            if result["success"]:
                st.success("ğŸ‰ AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("âœ… ì„±ê³µ", result["analyzed_count"])
                with col2:
                    st.metric("â­ï¸ ê±´ë„ˆëœ€", result["skipped_count"])
                with col3:
                    st.metric("âŒ ì‹¤íŒ¨", result["failed_count"])
                with col4:
                    st.metric("ğŸ“Š ì´ ì²˜ë¦¬", result["total_count"])
                
                # ì‹¤íŒ¨í•œ í•­ëª©ë“¤ í‘œì‹œ
                if result.get("failed_items"):
                    st.markdown("### âŒ ì‹¤íŒ¨í•œ í•­ëª©ë“¤")
                    with st.expander(f"ì‹¤íŒ¨í•œ {len(result['failed_items'])}ê°œ í•­ëª© ìƒì„¸ë³´ê¸°"):
                        for item in result["failed_items"]:
                            st.error(f"**ID: {item['id']}** - {item['error']}")
            else:
                st.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {result['error']}")

def execute_ai_analysis():
    """AI ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬) - ì•ˆì •í™” ë²„ì „"""
    try:
        # Supabase í´ë¼ì´ì–¸íŠ¸ 1íšŒ ìƒì„±/ì¬ì‚¬ìš©
        client = simple_client.get_client()
        if not client:
            return {"success": False, "error": "Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨"}

        # 1. ì „ì²´ ë°ì´í„° ê°œìˆ˜ (COMPLETE ìƒíƒœë§Œ)
        total_count = get_completed_crawling_data_count(client)
        if total_count == 0:
            return {"success": False, "error": "ë¶„ì„í•  í¬ë¡¤ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë””ë²„ê¹…: ì „ì²´ ë°ì´í„° ê°œìˆ˜ë„ í™•ì¸
        try:
            total_all_count = client.table("tb_instagram_crawling").select("id", count="exact").execute()
            st.info(f"ğŸ“Š ë°ì´í„° í˜„í™©: ì „ì²´ {total_all_count.count:,}ê°œ ì¤‘ ì™„ë£Œëœ í¬ë¡¤ë§ ë°ì´í„° {total_count:,}ê°œ (status='COMPLETE')")
        except:
            st.info(f"ì´ {total_count:,}ê°œì˜ ì™„ë£Œëœ í¬ë¡¤ë§ ë°ì´í„°(status='COMPLETE')ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        st.info("ë°°ì¹˜ ë‹¨ìœ„ë¡œ AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        batch_size = 50
        total_batches = (total_count + batch_size - 1) // batch_size

        analyzed_count = 0
        skipped_count = 0
        failed_count = 0
        processed_count = 0
        failed_items = []

        overall_progress_bar = st.progress(0)
        overall_status_text = st.empty()
        result_container = st.empty()

        UI_UPDATE_EVERY = 50  # ê°±ì‹  ì£¼ê¸° ì¤„ì´ê¸°

        for batch_num in range(total_batches):
            offset = batch_num * batch_size
            batch_data = get_completed_crawling_data(client, limit=batch_size, offset=offset)
            
            if not batch_data:
                break

            # ë°°ì¹˜ ì§„í–‰ UI (ê°„ì†Œí™”)
            batch_progress_bar = st.progress(0)
            batch_status_text = st.empty()

            for index, data in enumerate(batch_data):
                current_id = data.get('id', 'unknown')
                
                try:
                    # ì „ì²´/ë°°ì¹˜ ì§„í–‰ë¥ 
                    overall_progress = (processed_count + index + 1) / total_count
                    overall_progress_bar.progress(overall_progress)
                    overall_status_text.text(
                        f"ì „ì²´ ì§„í–‰: {processed_count + index + 1:,}/{total_count:,} (ë°°ì¹˜ {batch_num + 1}/{total_batches})"
                    )

                    batch_progress = (index + 1) / len(batch_data)
                    batch_progress_bar.progress(batch_progress)
                    batch_status_text.text(f"ë°°ì¹˜ {batch_num + 1} ì§„í–‰: {index + 1}/{len(batch_data)} - {current_id}")

                    # 1) ìµœê·¼ ë¶„ì„ ì—¬ë¶€ ë¨¼ì € (DB/API í˜¸ì¶œ ì ˆì•½)
                    if is_recently_analyzed_by_id(client, data["id"]):
                        skipped_count += 1
                        continue

                    # 2) ì…ë ¥ êµ¬ì„± (postsëŠ” ìë¥´ì§€ ì•ŠìŒ)
                    posts_content = data.get("posts", "") or ""
                    if not posts_content:
                        skipped_count += 1
                        continue

                    ai_input_data = {
                        "id": data.get("id", ""),
                        "description": data.get("description", "") or "",
                        "posts": posts_content
                    }

                    # 3) AI ë¶„ì„
                    analysis_result = perform_ai_analysis(ai_input_data)
                    if not analysis_result:
                        failed_items.append({"id": current_id, "error": "AI ë¶„ì„ ì‹¤íŒ¨"})
                        failed_count += 1
                        continue

                    # 4) ë³€í™˜
                    transformed_result = transform_to_db_format(ai_input_data, analysis_result, data["id"])
                    if not transformed_result:
                        failed_items.append({"id": current_id, "error": "ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨"})
                        failed_count += 1
                        continue

                    # 5) ì €ì¥
                    try:
                        save_ai_analysis_result(client, data, transformed_result, data["id"])
                        analyzed_count += 1
                    except Exception as se:
                        failed_items.append({"id": current_id, "error": f"ì €ì¥ ì‹¤íŒ¨: {str(se)}"})
                        failed_count += 1
                        continue

                    # UI ì—…ë°ì´íŠ¸(í¬ì†Œ)
                    if ((index + 1) % UI_UPDATE_EVERY == 0) or (index == len(batch_data) - 1):
                        with result_container.container():
                            st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²°ê³¼")
                            c1, c2, c3, c4 = st.columns(4)
                            c1.metric("âœ… ì„±ê³µ", analyzed_count)
                            c2.metric("â­ï¸ ê±´ë„ˆëœ€", skipped_count)
                            c3.metric("âŒ ì‹¤íŒ¨", failed_count)
                            c4.metric("ğŸ“Š ì´ ì²˜ë¦¬", processed_count + index + 1)

                except Exception as e:
                    failed_items.append({"id": current_id, "error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"})
                    failed_count += 1
                    continue

            processed_count += len(batch_data)
            batch_progress_bar.empty()
            batch_status_text.empty()

            # ë°°ì¹˜ ê°„ íœ´ì‹ ìµœì†Œí™”(ë˜ëŠ” ì œê±°)
            if batch_num < total_batches - 1:
                time.sleep(0.1)

        overall_progress_bar.progress(1.0)
        overall_status_text.text("ë¶„ì„ ì™„ë£Œ!")

        with result_container.container():
            st.markdown("### ğŸ‰ AI ë¶„ì„ ìµœì¢… ê²°ê³¼")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("âœ… ì„±ê³µ", analyzed_count, delta=f"{(analyzed_count/total_count*100):.1f}%")
            c2.metric("â­ï¸ ê±´ë„ˆëœ€", skipped_count, delta=f"{(skipped_count/total_count*100):.1f}%")
            c3.metric("âŒ ì‹¤íŒ¨", failed_count, delta=f"{(failed_count/total_count*100):.1f}%")
            c4.metric("ğŸ“Š ì´ ì²˜ë¦¬", total_count, delta="100%")

            if failed_items:
                st.markdown("### âŒ ì‹¤íŒ¨í•œ í•­ëª©ë“¤")
                with st.expander(f"ì‹¤íŒ¨í•œ {len(failed_items)}ê°œ í•­ëª© ìƒì„¸ë³´ê¸°"):
                    for item in failed_items:
                        st.error(f"**ID: {item['id']}** - {item['error']}")

        return {
            "success": True,
            "analyzed_count": analyzed_count,
            "skipped_count": skipped_count,
            "failed_count": failed_count,
            "total_count": total_count,
            "failed_items": failed_items
        }

    except Exception as e:
        return {"success": False, "error": str(e)}
